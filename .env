# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_LLM_MODEL=llama3:8b

# Embeddings model (recommended to pull an embed model)
# Example: ollama pull nomic-embed-text
OLLAMA_EMBED_MODEL=nomic-embed-text

# Retrieval / index
INDEX_PATH=storage/psalms_index.npz
PSALMS_PATH=data/psalm_data_main.json

# UI
APP_TITLE=PsalmSeeker.ai
